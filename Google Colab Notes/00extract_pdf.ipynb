{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22040,"status":"ok","timestamp":1722666794566,"user":{"displayName":"Ashlesh Mithur","userId":"11425720839438791647"},"user_tz":-120},"id":"sS3tpW15Gh78","outputId":"01b7e163-2129-4b0c-f860-178e03b289c6"},"outputs":[],"source":["from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11711,"status":"ok","timestamp":1722666813128,"user":{"displayName":"Ashlesh Mithur","userId":"11425720839438791647"},"user_tz":-120},"id":"_eoBGFWj7Slx","outputId":"477e456d-e6e9-4695-e560-dda485f193ec"},"outputs":[],"source":["!pip install pdfplumber\n","!pip install Pillow"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1722666813129,"user":{"displayName":"Ashlesh Mithur","userId":"11425720839438791647"},"user_tz":-120},"id":"4bCSToU8r1ZD"},"outputs":[],"source":["import os"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":223,"status":"ok","timestamp":1722666816654,"user":{"displayName":"Ashlesh Mithur","userId":"11425720839438791647"},"user_tz":-120},"id":"8IcbtrXfKrgg"},"outputs":[],"source":["import pdfplumber\n","import re\n","\n","from PIL import Image\n","import io\n","from google.colab import drive\n","from IPython.display import display"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jnPxrEUZK2hD"},"outputs":[],"source":["directory = '/content/drive/MyDrive/SustainabilityReports/Firm_ID/1/test'"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":263,"status":"ok","timestamp":1722666822710,"user":{"displayName":"Ashlesh Mithur","userId":"11425720839438791647"},"user_tz":-120},"id":"13di4mh44AhE"},"outputs":[],"source":["import os\n","import re\n","import pdfplumber\n","import logging"]},{"cell_type":"markdown","metadata":{"id":"pUvJ2sQQMZRQ"},"source":["\n","Code for removing tables and only keep text\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4037,"status":"ok","timestamp":1722666832591,"user":{"displayName":"Ashlesh Mithur","userId":"11425720839438791647"},"user_tz":-120},"id":"GdZEr-6ONh_W","outputId":"5f2d0fb1-fceb-4aef-8ac9-8aab7452f4c8"},"outputs":[],"source":["pip install tabula-py\n"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":309,"status":"ok","timestamp":1722685918991,"user":{"displayName":"Ashlesh Mithur","userId":"11425720839438791647"},"user_tz":-120},"id":"dK6gA2vYTwec"},"outputs":[],"source":["output_directory = '/content/drive/MyDrive/SustainabilityReports/Firm_ID/text/81_90'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pT7Xo2UbNCLf"},"outputs":[],"source":["convert_pdfs_in_directory(input_directory, output_directory)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":871,"status":"ok","timestamp":1722666853187,"user":{"displayName":"Ashlesh Mithur","userId":"11425720839438791647"},"user_tz":-120},"id":"T05wkeZL3f2X"},"outputs":[],"source":["import os\n","import logging\n","import re\n","import pandas as pd\n","import pdfplumber\n","import tabula"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1905070,"status":"ok","timestamp":1722687831083,"user":{"displayName":"Ashlesh Mithur","userId":"11425720839438791647"},"user_tz":-120},"id":"joG9temq3f0e","outputId":"40adda35-b19e-48f1-806a-6428560ecb82"},"outputs":[],"source":["# logging\n","logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n","\n","\n","logging.getLogger(\"org.apache.pdfbox\").setLevel(logging.ERROR)\n","\n","input_directory = '/content/drive/MyDrive/SustainabilityReports/Firm_ID/81'\n","csv_file_path = os.path.join('/content/drive/MyDrive/SustainabilityReports/Firm_ID/Results/DB', 'esg_report.csv')\n","\n","def remove_table_text(text, tables):\n","    \"\"\"\n","    Remove text lines that match table content.\n","\n","    Args:\n","        text (str): The extracted text from the PDF.\n","        tables (list): A list of DataFrames containing table content.\n","\n","    Returns:\n","        str: The cleaned text with table content removed.\n","    \"\"\"\n","    for table in tables:\n","        for _, row in table.iterrows():\n","            for cell in row:\n","                if isinstance(cell, str):\n","                    text = text.replace(cell, '')\n","    return text\n","\n","def extract_text_from_pdf(pdf_path):\n","    \"\"\"\n","    Extracts text from a PDF file, removes table-like structures, and returns sentences containing ESG-related keywords.\n","\n","    Args:\n","        pdf_path (str): The file path to the PDF.\n","\n","    Returns:\n","        list: A list of sentences containing ESG-related keywords.\n","    \"\"\"\n","    text = \"\"\n","    try:\n","        # Tabula\n","        tables = tabula.read_pdf(pdf_path, pages='all', multiple_tables=True)\n","\n","        # Extract text \n","        with pdfplumber.open(pdf_path) as pdf:\n","            for page in pdf.pages:\n","                page_text = page.extract_text()\n","                if page_text:\n","                    text += page_text.replace('\\n', ' ') + \" \"\n","                else:\n","                    text += f\"Page {page.page_number}: No text found. \"\n","\n","        # Remove table\n","        text = remove_table_text(text, tables)\n","    except Exception as e:\n","        logging.error(f\"An error occurred while processing {pdf_path}: {e}\")\n","        return []\n","\n","  \n","    sentence_endings = re.compile(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)\\s')\n","    sentences = [sentence.strip() for sentence in sentence_endings.split(text) if sentence.strip()]\n","\n","    #  keywords\n","    esg_keywords = [\n","        \"climate\", \"mitigation\", \"decarbonisation\", \"carbon\", \"ghg\", \"emission\",\n","        \"energy\", \"fuels\", \"fossil\", \"nuclear\", \"renewable\", \"scope 1\", \"scope 2\",\n","        \"scope 3\", \"pollution\", \"air\", \"water\", \"soil\", \"hazard\", \"concern\", \"recycle\",\n","        \"marine\", \"waste\", \"wastage\", \"hazardous\", \"danger\", \"dangerous\", \"radioactive\",\n","        \"human rights\", \"policy\", \"employee\", \"employees\", \"worker\", \"workers\", \"staff\",\n","        \"workplace\", \"accident\", \"accidents\", \"eliminate\", \"discriminate\", \"discrimination\",\n","        \"grievance\", \"grievances\", \"complaint\", \"complaints\",\n","        \"mitigate\", \"workforce\", \"board members\", \"male\", \"female\", \"management\",\n","        \"percent\", \"percentage\", \"number\", \"fatal\", \"fatalities\", \"death\", \"injury\", \"ill\",\n","        \"illness\", \"health\", \"life\", \"fine\", \"penalty\", \"penalties\", \"fines\", \"customer\",\n","        \"customers\", \"end users\", \"consumer\", \"consumers\", \"public\", \"society\",\n","        \"whistleblowing\", \"whistleblower\", \"whistle\", \"animal\", \"welfare\", \"training\",\n","        \"workshops\", \"business ethics\", \"business conduct\", \"disclosure\", \"corruption\",\n","        \"bribery\", \"favor\", \"illegal\", \"violate\", \"violation\", \"law\", \"laws\", \"anti-corruption\",\n","        \"anti-bribery\", \"anticorruption\", \"antibribery\", \"politics\", \"political\", \"finance\",\n","         \"contribution\", \"contributions\", \"payment\", \"wages\",\n","        \"salary\", \"esg\", \"environment\", \"social\", \"governance\", \"mental-health\", \"holiday\",\n","        \"bonus\"\n","    ]\n","\n","    #  pattern for matching ESG-related keywords\n","    keywords_pattern = re.compile(r'\\b(?:' + '|'.join(re.escape(keyword) for keyword in esg_keywords) + r')\\b', re.IGNORECASE)\n","\n","\n","    keyword_sentences = [sentence for sentence in sentences if keywords_pattern.search(sentence)]\n","\n","    return keyword_sentences\n","\n","def count_total_sentences(pdf_path):\n","    \"\"\"\n","    Counts the total number of sentences in the PDF after removing table content.\n","\n","    Args:\n","        pdf_path (str): The file path to the PDF.\n","\n","    Returns:\n","        int: The total number of sentences in the PDF.\n","    \"\"\"\n","    text = \"\"\n","    try:\n","        #  Tabula\n","        tables = tabula.read_pdf(pdf_path, pages='all', multiple_tables=True)\n","\n","        # Extract text from the PDF\n","        with pdfplumber.open(pdf_path) as pdf:\n","            for page in pdf.pages:\n","                page_text = page.extract_text()\n","                if page_text:\n","                    text += page_text.replace('\\n', ' ') + \" \"\n","                else:\n","                    text += f\"Page {page.page_number}: No text found. \"\n","\n","        # Remove table text\n","        text = remove_table_text(text, tables)\n","    except Exception as e:\n","        logging.error(f\"An error occurred while processing {pdf_path}: {e}\")\n","        return 0\n","\n","   \n","    sentence_endings = re.compile(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)\\s')\n","    sentences = [sentence.strip() for sentence in sentence_endings.split(text) if sentence.strip()]\n","\n","    return len(sentences)\n","\n","def process_pdfs(input_directory, output_directory, csv_file_path):\n","    \"\"\"\n","    Process all PDF files in the input directory, extracting ESG-related sentences and counting total sentences.\n","    Save the results in a CSV file.\n","\n","    Args:\n","        input_directory (str): The directory containing PDF files to process.\n","        output_directory (str): The directory to save the results.\n","        csv_file_path (str): The file path to the CSV file for storing the results.\n","    \"\"\"\n","    if not os.path.exists(output_directory):\n","        os.makedirs(output_directory)\n","\n","    # Prepare the CSV file\n","    if not os.path.exists(csv_file_path):\n","        df = pd.DataFrame(columns=[\"Company\", \"Year\", \"Total Sentences\", \"ESG Sentences\"])\n","        df.to_csv(csv_file_path, index=False)\n","\n","    for filename in os.listdir(input_directory):\n","        if filename.endswith('.pdf'):\n","            pdf_path = os.path.join(input_directory, filename)\n","\n","            # Extract firm name and year from filename\n","            match = re.match(r'^(.*?)_(\\d{4})\\.pdf$', filename)\n","            if match:\n","                company_name = match.group(1)\n","                year = match.group(2)\n","            else:\n","                logging.warning(f\"Filename {filename} does not match the expected pattern.\")\n","                continue\n","\n","            esg_sentences = extract_text_from_pdf(pdf_path)\n","            total_sentences = count_total_sentences(pdf_path)\n","\n","            # CSV file\n","            df = pd.read_csv(csv_file_path)\n","            new_row = {\n","                \"Company\": company_name,\n","                \"Year\": year,\n","                \"Total Sentences\": total_sentences,\n","                \"ESG Sentences\": len(esg_sentences)\n","            }\n","            df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n","            df.to_csv(csv_file_path, index=False)\n","\n","            # text file\n","            output_file_path = os.path.join(output_directory, f\"{os.path.splitext(filename)[0]}.txt\")\n","            with open(output_file_path, 'w') as output_file:\n","                output_file.write(f\"Total sentences in the PDF after removing tables: {total_sentences}\\n\")\n","                output_file.write(\"ESG-related sentences:\\n\")\n","                for sentence in esg_sentences:\n","                    output_file.write(f\"{sentence}\\n\")\n","\n","            logging.info(f\"Processed {filename}\")\n","\n","\n","process_pdfs(input_directory, output_directory, csv_file_path)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNKx8xrc7GGErsNyg1qioxx","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
